{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2093a3e1-23da-4b72-9d9e-fba415e93261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! TDC is working in Jupyter.\n",
      "\n",
      "Columns: ['Drug_ID', 'Drug', 'Y']\n",
      "\n",
      "First 3 rows:\n",
      "                 Drug_ID                                              Drug  Y\n",
      "0            Propanolol                  CC(C)NCC(O)COc1cccc2ccccc12.[Cl]  1\n",
      "1  Terbutylchlorambucil            CC(C)(C)OC(=O)CCCc1ccc(N(CCCl)CCCl)cc1  1\n",
      "2                 40730  CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23  1\n",
      "\n",
      "Shape: (2030, 3)\n",
      "\n",
      "Label distribution:\n",
      " Y\n",
      "1    0.764039\n",
      "0    0.235961\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import ADME\n",
    "data = ADME(name='BBBP_Martins')\n",
    "df = data.get_data()\n",
    "\n",
    "print(\"SUCCESS! TDC is working in Jupyter.\")\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 3 rows:\\n\", df.head(3))\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nLabel distribution:\\n\", df['Y'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab833d6-006a-46ea-9674-2ba9bef216e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (4.50.3)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (2.19.2)\n",
      "Requirement already satisfied: rdkit in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (2023.9.6)\n",
      "Requirement already satisfied: tdc in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (0.1)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: gradio in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (6.6.0)\n",
      "Requirement already satisfied: shap in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (0.49.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (3.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (2026.2.19)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (0.7)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from rdkit) (12.1.1)\n",
      "Requirement already satisfied: wikipedia in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (1.4.0)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (1.42.57)\n",
      "Requirement already satisfied: python-vlc in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (3.0.21203)\n",
      "Requirement already satisfied: chatterbot in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (1.2.12)\n",
      "Requirement already satisfied: pyserial in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (3.5)\n",
      "Requirement already satisfied: speechrecognition in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (3.14.5)\n",
      "Requirement already satisfied: google-speech in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from tdc) (1.2.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (4.12.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.133.1)\n",
      "Requirement already satisfied: ffmpy in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.1.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (3.11.7)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (2025.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.52.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from gradio) (0.41.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.4.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2026.2.25)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: click>=8.2.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.3.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from shap) (1.15.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from shap) (0.64.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from shap) (3.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from aiohttp->datasets) (1.22.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from numba>=0.54->shap) (0.46.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.57 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from boto3->tdc) (1.42.57)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from boto3->tdc) (1.1.0)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from boto3->tdc) (0.16.0)\n",
      "Requirement already satisfied: mathparse<0.3,>=0.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from chatterbot->tdc) (0.2.7)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=2.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from chatterbot->tdc) (2.0.47)\n",
      "Requirement already satisfied: spacy<3.9,>=3.8 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from chatterbot->tdc) (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (0.24.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from spacy<3.9,>=3.8->chatterbot->tdc) (69.5.1)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9,>=3.8->chatterbot->tdc) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9,>=3.8->chatterbot->tdc) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<3.9,>=3.8->chatterbot->tdc) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from weasel<0.5.0,>=0.4.2->spacy<3.9,>=3.8->chatterbot->tdc) (7.5.1)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy<3.9,>=3.8->chatterbot->tdc) (1.17.3)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from google-speech->tdc) (1.4.4)\n",
      "Requirement already satisfied: web_cache>=1.1.0 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from google-speech->tdc) (1.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from wikipedia->tdc) (4.14.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/anaconda3/envs/dd27-clean/lib/python3.10/site-packages (from beautifulsoup4->wikipedia->tdc) (2.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0226 23:45:14.162000 30923 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/yousuf/.matplotlib is not a writable directory\n",
      "Matplotlib created a temporary cache directory at /var/folders/4s/rj_sy56d06508gj9z8g3lwhw0000gn/T/matplotlib-hlvvhaux because there was an issue with the default path (/Users/yousuf/.matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Matplotlib is building the font cache; this may take a moment.\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:45:24] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|████████████████████████████████████| 2030/2030 [00:00<00:00, 7002.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaffold split sizes: 1421 203 406\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Environment Setup and Data Acquisition\n",
    "!pip install transformers datasets rdkit tdc evaluate gradio shap torch scikit-learn\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from tdc.single_pred import ADME\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import gradio as gr\n",
    "from tdc import single_pred\n",
    "\n",
    "# Load and prepare data\n",
    "\n",
    "data = single_pred.ADME(name='BBBP_Martins')\n",
    "df = data.get_data()\n",
    "\n",
    "# Validate SMILES\n",
    "def is_valid_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol is not None\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df = df[df['Drug'].apply(is_valid_smiles)]  # Filter invalid\n",
    "df = df.drop_duplicates(subset=['Drug'])    # Drop duplicates\n",
    "\n",
    "\n",
    "# Use TDC's built-in scaffold split\n",
    "split = data.get_split(method='scaffold')  # or 'scaffold_balanced'\n",
    "\n",
    "train_df = split['train']\n",
    "val_df   = split['valid']\n",
    "test_df  = split['test']\n",
    "\n",
    "print(\"Scaffold split sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# Proceed with your rename / Dataset creation\n",
    "train_ds = Dataset.from_pandas(train_df.rename(columns={'Drug': 'SMILES', 'Y': 'labels'}))\n",
    "val_ds   = Dataset.from_pandas(val_df.rename(columns={'Drug': 'SMILES', 'Y': 'labels'}))\n",
    "test_ds  = Dataset.from_pandas(test_df.rename(columns={'Drug': 'SMILES', 'Y': 'labels'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7605c503-b2cf-4d8f-8f52-4492710a60d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Quick Sanity Check ===\n",
      "Train dataset size: 1421\n",
      "Val dataset size: 203\n",
      "Test dataset size: 406\n",
      "\n",
      "Example from train_ds:\n",
      "{'Drug_ID': 'Terbutylchlorambucil', 'SMILES': 'CC(C)(C)OC(=O)CCCc1ccc(N(CCCl)CCCl)cc1', 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Quick Sanity Check ===\")\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Val dataset size:\", len(val_ds))\n",
    "print(\"Test dataset size:\", len(test_ds))\n",
    "print(\"\\nExample from train_ds:\")\n",
    "print(train_ds[0]) ##  {'SMILES': '...', 'labels': 0 or 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960148a2-9cac-4f71-8654-b85c04483190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared corrupted model cache.\n",
      "Cache cleared. Ready to retry model loading.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "cache_dir = os.path.expanduser(\"~/.cache/huggingface/hub\")\n",
    "model_cache = os.path.join(cache_dir, \"models--DeepChem--ChemBERTa-77M-MLM\")\n",
    "if os.path.exists(model_cache):\n",
    "    shutil.rmtree(model_cache)\n",
    "    print(\"Cleared corrupted model cache.\")\n",
    "else:\n",
    "    print(\"No local cache found for this model — clean start.\")\n",
    "\n",
    "print(\"Cache cleared. Ready to retry model loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb2b3a6-7e08-4493-bcc7-3979721c667d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72b0f7821764a7cb03734083beda6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6e2520c79842d5a6d3e21d5b937a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5150f2db289d4fe9abda1e71f4f21fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bf84832b24414497345ea89129e86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21e88b327f4450a890f407827541d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bfef9da22d41c5ad040136936e58d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7696845b504e57a5af3ab1eac30bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/420 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./chemberta_model and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from local files!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "local_path = './chemberta_model'  \n",
    "tokenizer = AutoTokenizer.from_pretrained('DeepChem/ChemBERTa-77M-MLM')  # Tokenizer still from HF\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    local_path,  # ← Point to local folder\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully from local files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f82acc-b8db-48d0-bd43-c7d56a7d043d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72052f33a7a448eb437ae3ed7d4cfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97242bb88564512b7cf9fae97126e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c2afeeaa964fa085e1c1c20a133ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n",
      "Example input_ids length: 512\n"
     ]
    }
   ],
   "source": [
    "## Step 3 : Tokenization\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['SMILES'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_ds.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# Setting format for PyTorch\n",
    "tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(\"Example input_ids length:\", len(tokenized_train[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb4f11f-9c8f-4382-90ef-0ef80c1c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    auc_score = roc_auc_score(labels, p.predictions[:, 1])\n",
    "    precision, recall, _ = precision_recall_curve(labels, p.predictions[:, 1])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return {'accuracy': acc, 'f1': f1, 'roc_auc': auc_score, 'pr_auc': pr_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b4d0ff-5d8d-4466-b1f8-f471497dff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting manual fine-tuning on CPU...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Move model to CPU explicitly\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# DataLoader (batch size 8, shuffle training)\n",
    "train_loader = DataLoader(tokenized_train, batch_size=8, shuffle=True)\n",
    "\n",
    "print(\"Starting manual fine-tuning on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbcef63-8352-41a4-b805-3240ae8f36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 178/178 [02:28<00:00,  1.20it/s, batch_loss=0.4887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 completed. Average loss: 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 178/178 [02:24<00:00,  1.23it/s, batch_loss=0.1737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 completed. Average loss: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 178/178 [02:28<00:00,  1.20it/s, batch_loss=0.1259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 completed. Average loss: 0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Progress bar for batches\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/3\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/3 completed. Average loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d99355b-2c0b-446e-b3f7-6d9a3bbebe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Model saved to ./dd27_scaffold\n"
     ]
    }
   ],
   "source": [
    "# Saving fine-tuned model\n",
    "model.save_pretrained('./dd27_scaffold')\n",
    "tokenizer.save_pretrained('./dd27_scaffold')\n",
    "print(\"Training complete! Model saved to ./dd27_scaffold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6f7a6-5953-47aa-9484-8d5089dd0819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fb962-69ef-437f-8f2c-3f8217af6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training for 10 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cc3ce22-820b-4e1b-a400-98474cd87eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(600, 384, padding_idx=1)\n",
       "      (position_embeddings): Embedding(515, 384, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.144, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.109, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.144, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=464, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=464, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.144, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (dropout): Dropout(p=0.144, inplace=False)\n",
       "    (out_proj): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('./dd27_scaffold')\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f892ef-86bc-4e50-8cdd-d79ec5722958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████| 178/178 [02:28<00:00,  1.20it/s, batch_loss=1.0247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 completed. Average loss: 0.3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████| 178/178 [02:36<00:00,  1.14it/s, batch_loss=0.2202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 completed. Average loss: 0.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████| 178/178 [02:26<00:00,  1.21it/s, batch_loss=0.2997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 completed. Average loss: 0.3427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████| 178/178 [02:25<00:00,  1.22it/s, batch_loss=0.6921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/3 completed. Average loss: 0.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████| 178/178 [02:29<00:00,  1.19it/s, batch_loss=0.5721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/3 completed. Average loss: 0.3474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████| 178/178 [02:26<00:00,  1.21it/s, batch_loss=0.1620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/3 completed. Average loss: 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████| 178/178 [02:23<00:00,  1.24it/s, batch_loss=0.2987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/3 completed. Average loss: 0.3417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████| 178/178 [02:31<00:00,  1.18it/s, batch_loss=0.2888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/3 completed. Average loss: 0.3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█████████| 178/178 [02:26<00:00,  1.22it/s, batch_loss=0.1025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/3 completed. Average loss: 0.3481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████| 178/178 [02:39<00:00,  1.12it/s, batch_loss=0.7226]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/3 completed. Average loss: 0.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Progress bar for batches\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/3 completed. Average loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f579cec-b206-437a-a147-0877a6c91e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Model saved to ./dd27_scaffold\n"
     ]
    }
   ],
   "source": [
    "# Saving fine-tuned model\n",
    "model.save_pretrained('./dd27_scaffold')\n",
    "tokenizer.save_pretrained('./dd27_scaffold')\n",
    "print(\"Training complete! Model saved to ./dd27_scaffold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2409ae3-751f-4d1c-9868-38b831d65a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff67a488-ada3-4d7b-b9a0-3f3161a2a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 26/26 [00:05<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Evaluation ===\n",
      "Accuracy:     0.8448\n",
      "F1 Score:     0.9038\n",
      "ROC-AUC:      0.8321\n",
      "PR-AUC:       0.9413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu') # version mismatch with accelerate so training on CPU (avoiding MPS)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Creating test DataLoader\n",
    "test_loader = DataLoader(tokenized_test, batch_size=16, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "print(\"Running evaluation on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "        }\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[:, 1].cpu().numpy()  # Class 1 - permeable\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_probs.extend(probs)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Computing metric\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(\"\\n=== Test Set Evaluation ===\")\n",
    "print(f\"Accuracy:     {accuracy:.4f}\")\n",
    "print(f\"F1 Score:     {f1:.4f}\")\n",
    "print(f\"ROC-AUC:      {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC:       {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d89c2-ca03-4184-971c-4f2ee0de3939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DD 2.7 Clean (Python 3.10)",
   "language": "python",
   "name": "dd27-clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
